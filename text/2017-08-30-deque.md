# Summary

This RFC proposes [an implementation of work-stealing double-ended queue][impl] (deque) on
Crossbeam, and proves its correctness. Once this RFC is accepted, the implementation will be moved
to the [crossbeam-rs organization][crossbeam-rs].



# Motivation

Prior implementations of deque are not fully optimized yet, leaving non-negligible room for
performance improvement. However, it is unclear how to further optimize the implementation while
guaranteeing its correctness. We aim to resolve this issue by proving an optimized implementation.



# Detailed design

In this section, we present a pseudocode of deque, and prove that (1) it is safe in the C/C++ memory
consistency model, and (2) it is functionally correct, i.e. it acts like a deque.


## Semantics of C/C++ relaxed-memory concurrency

For the semantics of C/C++ relaxed-memory concurrency on which the deque implementation is based, we
use the state-of-art [promising semantics][promising]. For a gentle introduction to the semantics,
we refer the reader to [this blog post][synch-patterns].

One caveat of the original promising semantics is its lack of support for memory allocation. In this
RFC, we use the following semantics for memory allocation:

- In the original promising semantics, a timestamp was a non-negative quotient number: `Timestamp =
  Q+`. Now we define `Timestamp = Option<Q+>`, where `None` means the location is
  unallocated. Suppose `None < Some(t)` for all `t`.

- At the beginning, the thread's view is `None` for all the locations. When a thread allocates a
  location, its view on the location becomes `0`.

- If a thread is reading a location and it's view on the location is `None`, i.e. it is unallocated
  in the thread's point of view, the behavior is undefined.

We believe this definition is compatible with all the results presented in the
[paper][promising]. We are working on updating [the Coq formalization][promising-coq].


## Proposed implementation

A work-stealing deque is owned by the "owner" thread, which can push items to and pop items from the
"bottom" end of the deque. Other threads, which we call "stealers", try to steal items from the
"top" end of the deque. The following is a summary of its interface:

```rust
impl<T: Send> Deque<T> { // Send + !Sync
    pub fn new() -> Self { ... }
    pub fn stealer(&self) -> Stealer<T> { ... }

    pub fn push(&self, value: T) { ... }
    pub fn pop(&self) -> Option<T> { ... } // None if empty
}

impl<T: Send> Stealer<T> { // Send + Sync
    pub fn steal(&self) -> Option<T> { ... }
}
```

Chase and Lev proposed [an efficient implementation of deque][chase-lev] on sequential consistency,
and LÃª et. al. proposed [its variant for ARM and C/C++ relaxed-memory
concurrency][weak-chase-lev]. This RFC presents an even more optimized variant for C/C++.

Chase and Lev's implementation of deque consists of (1) the `bottom` index for the worker, (2) the
`top` index for both the worker and the stealers, and (3) the underlying `buffer` that contains
items. When the buffer is too small or too large, the worker may replace it with one with more
appropriate size:

```rust
struct<T: Send> Inner<T> {
    bottom: AtomicUsize,
    top: AtomicUsize,
    buffer: Ptr<Buffer<T>>,
}

impl<T: Send> Inner<T> {
    ...
}
```

The `Deque` and `Stealer` structs have a counted reference to the implementation, and delegate
method invocations to it:

```rust
struct<T: Send> Deque<T> {
    inner: Arc<Inner<T>>,
}

impl<T:Send> Deque<T> {
    fn push(...) {
        self.inner.push(...)
    }

    ...
}

...
```

The following is pseudocode for `Inner<T>`'s `fn push()`, `fn try_pop()`, and `fn steal()`:

```rust
pub fn push(&self, t: T) {
    'L100: epoch::unprotected(|scope| {
    'L101:     let b = self.bottom.load(Relaxed);
    'L102:     let t = self.top.load(Relaxed);
    'L103:     let mut buffer = self.buffer.load(Relaxed, scope);

    'L104:     let cap = buffer.get_capacity();
    'L105:     if b - t >= cap {
    'L106:         buffer = self.resize(buffer, b, t, cap, cap * 2, scope);
    'L107:     }

    'L108:     buffer.write(b % buffer.get_capacity(), t);
    'L109:     self.bottom.store(b + 1, Release);
    'L110: })
}

pub fn try_pop(&self) -> Option<T> {
    'L200: epoch::unprotected(|scope| {
    'L201:     let b = self.bottom.load(Relaxed);
    'L202:     self.bottom.store(b - 1, Relaxed);
    'L203:     fence(SeqCst);
    'L204:     let t = self.top.load(Relaxed);
    'L205:     let len = b - t;

    'L206:     if len <= 0 {
    'L207:         self.bottom.store(b, Relaxed);
    'L208:         return None;
    'L209:     }

    'L210:     let buffer = self.buffer.load(Relaxed, scope);
    'L211:     let mut value = Some(buffer.read((b - 1) % buffer.get_capacity()));

    'L212:     if len == 1 {
    'L213:         if self.top.compare_and_swap(t, t + 1, Release).is_err() {
    'L214:             mem::forget(value.take());
    'L215:         }
    'L216:         self.bottom.store(b, Relaxed);
    'L217:     }

    'L218:     let cap = buffer.get_capacity();
    'L219:     if len < cap / 4 {
    'L220:         self.resize(buffer, b, t, cap, cap / 2, scope);
    'L221:     }

    'L222:     value
    'L223: })
}

fn resize(&self, old, b, t, cap_old, cap_new, scope) {
    'L300: let new = Buffer::new(cap_new);
    'L301: ... // copy data from old to new
    'L302: let new = Owned::new(new).into_ptr(scope);
    'L303: self.buffer.store(new, Release);

    'L304: epoch::pin(|scope| {
    'L305:     scope.defer_drop(old);
    'L306: });

    'L307: new
}

pub fn steal(&self) -> Option<T> {
    'L400: let mut t = self.top.load(Relaxed);

    'L401: epoch::pin_fence(|scope| { // fence(SeqCst)
    'L402:     loop {
    'L403:         let b = self.bottom.load(Acquire);
    'L404:         if b - t <= 0 {
    'L405:             return None;
    'L406:         }

    'L407:         let buffer = self.buffer.load(Acquire, scope);
    'L408:         let value = buffer.read(t % buffer.size());

    'L409:         match self.top.compare_exchange(t, t + 1, Release) {
    'L410:             Ok(_) => return Some(value),
    'L411:             Err(t_old) => {
    'L412:                 mem::forget(value);
    'L413:                 t = t_old;
    'L414:                 fence(SeqCst);
    'L415:             }
    'L416:         }
    'L417:     }
    'L418: })
}
```


## Safety

We first prove that the implementation is memory-safe, i.e. it does not invoke undefined behavior
due to illegal memory accesses. We discuss two possible causes of undefined behavior: data race and
invalid pointer dereference.


### Presence of Data Races

In the C/C++ standard, if two threads race on a non-atomic object, i.e. they concurrently access it
and at least one of them writes to it, then the program's behavior is undefined. Unfortunately, in
fact, `fn push(): 'L108` and `fn steal(): 'L408` may race on `buffer`. For example, the scheduler
may stop a `steal()` invocation right after `'L401` so that `t` read in `'L400` may be arbitrarily
stale. Now, suppose that in a concurrent `push()` invocation, `b` equals to `t +
buffer.get_capacity()` and it is overwriting a value to `buffer`'s `(b % buffer.get_capacity())`-th
element. At the same time, the `steal()` invocation may wake up and read `buffer`'s `(t %
buffer.get_capacity())`-th element, incurring a data race with the `push()`.

In order to avoid data races, we may use an atomic buffer. However, the deque's item may be large,
and [atomic accesses to large objects are probably blocking][cppatomic], which is highly
undesirable. Thus there is a genuine data race in Chase and Lev's deque w.r.t. the C/C++ standard.

We make a rather bold claim: **data races are NOT undefined behavior**, but a racing reader may read
an unspecified value (or the `poison` value in the LLVM lingo), and racing writers may write values
word-by-word. Note that this is an over-approximatin of what is currently defined in the promising
semantics.


### Absence of Invalid Pointer Dereference

<!-- By invalid pointer dereference we mean (1) null pointer dereference, (2) use-after-free, or (3)
-->
<!-- free-after-free. -->

It boils down to proving the safety of every access to the buffer pointed-to by `Inner`'s
`self.buffer`, (1) since the other shared locations, namely `self.bottom` and `self.top`, are just
integers, and (2) accesses to thread-local storage are straightforwardly safe. It is worth noting
that while the deque is shared among the owner (`Deque<T>`) and its stealers, only the owner is able
to call `fn push()`, `fn try_pop()`, and `fn resize()`, thereby modifying `self.bottom` and
`self.buffer`.

After `self.buffer` is initialized, it is modified only by the owner in `fn resize(): 'L303`. Since
elements inside a buffer is always accessed modulo the buffer's capacity (`'L108`, `'L211`) and
buffer's size is always nonzero, there is no buffer overrun.

Thus it remains to prove that the buffer is not used after freed. Thanks to Crossbeam, we don't need
to take care of all the details of memory reclamation; as a user of Crossbeam, we only need to prove
that:

- When a buffer is `defer_drop()`ped (`'L305`), there is no longer a reference to the buffer in the
  shared memory, and no concurrent mutator introduces the reference to the memory again.

  You can easily check these properties because the owner basically "owns" the buffer: only the
  owner introduces/eliminates references to a buffer to/from the shared memory. In particular,
  before a buffer is `defer_drop()`ped at `'L305`, the only reference to the buffer via
  `self.buffer` is removed at `'L303`.

- Inside `fn epoch::unprotected()`, we should not `defer_drop()` an object that another thread is
  accessing, and should not access an object that another thread is `defer_drop()`ping.

  It is indeed the case because (1) a buffer is `defer_drop()`ped only by the owner in a protected
  scope, and (2) stealers does not use an unprotected scope.



## Functional Correctness

A more interesting question than just memory safety is: does it act like a deque?

In order to answer the question, we first define what does the phrase "act like" means. We say a
shared object acts like a deque if (1) it is **linearlizable** as a deque, and (2) a matching pair
of `push()` and `steal()` synchronize like a matching pair of a release-store and an acquire-load.


### Specification 1: Linearizability

More precisely, a shared object is a linearizable as a deque if the following holds:

> Suppose `i_1`, ..., `i_n` are the method invocations (e.g. `push()`, `try_pop()`, `steal()`
> invocations) to the shared object in a single execution, possibly from multiple threads. Then
> there exists a permutation `j_1`, ..., `j_n` of those invocations, which we call **"linearization
> order"**, denoted by `<`, that satisfies the following properties:
>
> - (VIEW) For all `x` and `y`, if `j_x -view-> j_y`, then `x < y` holds;
>
> - (SEQ) The invocations `j_1`, ..., `j_n` return outputs **as if** the methods are sequentially
>   (i.e. non-concurrently) executed to a deque one-by-one in the linearization order.

Here, by `view_beginning(j)` and `view_end(j)` we mean the thread `j`'s view at the beginning and
the end of the invocation. A view `v1` is less than or equal to another view `v2`, denoted by `v1 <=
v2`, if for any location `l`, `v1[l] <= v2[l]` holds; and `v1` is less than `v2`, denoted by `v1 <
v2`, if (1) `v1 <= v2`, and (2) there exists a location `l` such that `v1[l] < v2[l]`. By `j_x
-view-> j_y` we mean `view_end(j_x) < view_beginning(j_y)`;


This definition of linearizability is a view-oriented interpretation of the [the traditional
definition][linearizability]. But it slightly differs from the traditional definition because it
cannot properly distinguish invocations with the same view. For example, suppose the client code
looks like:

```rust
fn client() {
    i_1();
    i_2();
}
```

and `view_beginning(i_1) = view_end(i_1) = view_beginning(i_2) = view_end(i_2)`. By definition, `i_2
-> i_1` is a legit linearization order, yet actually `i_1` should be ordered before `i_2` because it
is so in the _program order_ (think: the execution order in a single thread). However, we do not
regard it a serious problem: if `i_1` and `i_2` do not change the view, they are read-only, and
should not change the state of the shared object. Thus it doesn't matter whether `i_1` is considered
to be before or after `i_2`.  <!-- If we want to be pedantic, we may alternatively require every
method to write something to a --> <!-- thread-local storage, effectively disallowing that the views
at --> <!-- the beginning and the end should differ. We can use this storage only in the proof, and
optimize out --> <!-- in the runtime. -->


### Specification 2: Synchronization of `push()` and `steal()`

In addition to linearizability, we require that matching `push()` and /`steal()` operations should
synchronize like a matching pair of a release-store and an acquire-load:

> (SYNCH) If a value is `push()`ed by an invocation `I` and then `steal()`ed by `J`, then
> `view_beginning(I) <= view_end(J)` holds.

Note that a similar property for a matching pair of `push()` and `try_pop()` is a corollary of
linearizability, as only the owner may call `push()` and `try_pop()` and `push()` should be before
`try_pop()` in the program order.


### Construction of Linearization Order

Suppose there are `n` invocations to the deque so far. We classify the invocations as follows:

- `push^x`: an element at the index `x` is pushed by the owner;
- `pop^x`: an element at the index `x` is popped by the owner in the fast path, i.e. the case that
  the branch at `'L212` is not taken.
- `pop_steal^x`: an element at the index `x` is popped by the owner in the slow path, i.e. the case
  that the branch at `'L212` is taken.
- `pop_empty^x`: the owner fails to pop an element because it's empty, and it read `x` from
  `self.bottom` at `'L201`.
- `steal^x`: an element at the index `x` is stolen.
- `steal_empty^x`: a stealer fails to steal an element because it's empty, and it read `x` from
  `t`. Also, it didn't read `b` from the value stored in `'L202`.
- `steal_empty_irregular^x`: similar to `steal_empty()^x`, but it read `b` from the value stored in
  `'L202`.

Furthermore, we define the following super-classes:

- `OWNER` = `Union_i {push^x U pop^x U pop_steal^x U pop_empty^x}`
- `STEALER` = `Union_i {steal^x U steal_empty^x U steal_empty_irregular^x}`
- `STEAL^x` = `pop_steal^x U steal^x`
- `EMPTY^x` = `pop_empty^x U steal_empty^x U steal_empty_irregular^(x-1)`

We construct a linearization order `L` for a given program execution as follows:

- List `OWNER` invocations, in the same order as the program execution (i.e. in the program
  order). Let `L` be such an order.

- Insert `STEALER` invocations in `L` as follows. For each `x`, in the increasing order from 0 to
  infinity, until all invocations are inserted in `L`:

    + Insert `EMPTY^x` invocations one-by-one in `L`. Each invocation `I` should be inserted after
      `STEAL^(x-1)` invocations, and after those invocations `J` such that `J -view-> I` holds
      (cf. the `(VIEW)` rule). Insert `I` at the earliest possible position.

    + Insert the `steal^x` invocation, if exists, in `L`. It should be inserted after `push^x`,
      `STEAL^(x-1)`, and `EMPTY^x`, and after those invocations `J` such that `J -view-> steal^x`
      holds. Insert it at the earliest possible position.


### Lemma

Before delving into the main proof, we first prove several lemmas on `L`.


> Lemma (VIEW-OWNER): Suppose `L_i` is in `OWNER`, and `L_i -view-> L_j`. Then `i < j` holds.

If `L_j` is also in `OWNER`, then `i < j` by the construction of `L`. Otherwise, `L_j` is in
`STEALER`, then `L_j` should have been inserted after `L_i` by the construction of `L`, concluding
that `i < j`.


> Lemma (VIEW-STEALER): Suppose `i < k`, `L_i` is `OWNER`, and `L_k` is `STEALER`. Then there exists
> `j` such that:
>
> - `i <= j <= k`;
>
> - `L_i -view-> L_j` or `i = j`; and
>
> - If `L_k` is `EMPTY^x` for some `x`, then `L_j` is `push^y` for some `0 <= y < x`, `STEAL^y` for
>   some `0 <= y < x`, or `EMPTY^y` for some `0 <= y < x`.  Otherwise, if `L_k` is `steal^x` for
>   some `x`, then `L_j` is `push^y` for some `0 <= y <= x`, `STEAL^y` for some `0 <= y < x`, or
>   `EMPTY^y` for some `0 <= y <= x`.

TODO


### Proof

We prove every suffix of `L` is linearization by induction on the size of the suffix. Let `L_j` be
the `j`-th invocation in `L` (the index begins at 0), and `L[a..b)` be the sublist of `L` from
`a`-th to `(b-1)`-th invocations. Then `L[0..j)` is the suffix of `L` with `j` invocations.
`L[0..0)` is trivially linearization. Now let's prove that if `L[0..j)` is a linearization, and so
is `L[0..(j+1))`. Let `b_j` and `t_j` be the bottom and top index after `L[0..j)` according to the
sequential specification of deque. We do a case analysis on `L_j`, which is the last invocation of
`L[0..(j+1))`:

- Case that `L_j` is classified as `push^x`.

  + `(VIEW)`: by `(VIEW-OWNER)`.

  + `(SEQ)`: Since only the owner writes to `self.bottom`, the value read at `'L101` in `L_j` equals
    to `b_j` and the value written at `'L109` in `L_j` equals to `b_(j+1)`. Thus `(SEQ)` trivially
    holds for `L_j`.

- Case that `L_j` is classified as `pop^x`.

  + `(VIEW)`: by `(VIEW-OWNER)`.

  + `(SEQ)`: Since `pop()` decrements `self.bottom`, `b_(j+1) = b_j - 1`. So it is sufficient to
    prove that `t_j <= x`. We prove by contradiction: we suppose `t_j > x`, and derive a
    contradiction.

    `L_j` read `x+1` from `self.bottom` at `'L201`, and wrote `x` to `self.bottom` at `'L202`. Also,
    the value `y` read from `self.top` at `'L204`, should be less than `x`: `y < x`.

    Since `self.top` is incremented only by `STEAL` invocations, there should be `i < j` such that
    `L_i` is `STEAL^x`. If it is `pop_steal^x`, then `y >= x+1` should hold, which is a
    contradiction. If it is `steal^x`, `L_i` read `x` from `self.top` at `'L400` and the value `z`
    read from `self.bottom` at `'L403` should be bigger than `x`: `z > x`.
    
    Since `L_j`'s load from `self.top` at `'L204` is coherence-before `L_i`'s load from `self.top`
    at `'L400`, the view of `L_j` at `'L203` should be less than the view of `L_i` at `'L401` via
    positive piggybacking synchronization of `SeqCst` fences. Thus `z` is coherence-after the value
    written in `L_j` at `'L202`. (`z` cannot be the value written at `'L202`, which is `x`, since
    `z` should be bigger than `x`.) Thus there should be a `push^x` invocation after `L_j`. Let it
    be `L_k` where `j < k` holds. Then by the construction of `L`, `k < i` should hold, which
    contradicts with `i < j < k`.
    
    TODO: it returns the right value?

- Case that `L_j` is classified as `pop_steal^x`.

  + `(VIEW)`: by `(VIEW-OWNER)`.

  + `(SEQ)`: TODO

- Case that `L_j` is classified as `pop_empty^x`.

  + `(VIEW)`: by `(VIEW-OWNER)`.

  + `(SEQ)`: TODO

- Case that `L_j` is classified as `steal^x`.

  + `(VIEW)`: TODO
  + `(SEQ)`: TODO
  + `(SYNCH)`: TODO

- Case that `L_j` is classified as `steal_empty^x`.

  + `(VIEW)`: TODO
  + `(SEQ)`: TODO

- Case that `L_j` is classified as `steal_empty_irregular^x`.

  + `(VIEW)`: TODO
  + `(SEQ)`: TODO



# Alternatives

## The current implementation

A reader may notice that the pseudocode differs
from [the current implementation in Crossbeam][current-impl]. We believe the current implementation
is buggy w.r.t. the C11 memory model, because it uses SC reads/writes that do not provide the
interleaving property. See [RFC #6][rfc6] for more details.

## Target-dependent implementation

Alternatively, we can write a deque for each target architecture in order to achieve better
performance. Indeed, [this paper][TODO] presented a variant of Chase and Lev's deque which issues
less `MFENCE` in `fn TODO()` than the x86 compilation result of the proposed implementation. Also, a
variant in [this paper][weak-chase-lev] for POWER doesn't issue an `isync` fence, while the proposed
implementation issues one. These further optimizations are left as future work.


## Ensuring correctness by testing

TODO: In order to ensure the correctness of Crossbeam's implementation, one may thoroughly test it
using real-world workloads. However, as [Dijkstra pointed out][dijkstra] in the early days, "testing
shows the presence, not the absence of bugs".



# Unresolved questions

TODO: Is it *really* the most efficient implementation in the C11 memory model?

Is there any soundness gap in above description? More ambitiously, can we formally verify the
correctness of the proposed implementation?


[chase-lev]: https://pdfs.semanticscholar.org/3771/77bb82105c35e6e26ebad1698a20688473bd.pdf
[weak-chase-lev]: http://www.di.ens.fr/~zappa/readings/ppopp13.pdf
[impl]: https://github.com/jeehoonkang/crossbeam-deque
[crossbeam-rs]: https://github.com/crossbeam-rs
[promising]: http://sf.snu.ac.kr/promise-concurrency/
[promising-coq]: https://github.com/snu-sf/promising-coq
[synch-patterns]: https://jeehoonkang.github.io/2017/08/23/synchronization-patterns.html
[current-impl]: https://github.com/crossbeam-rs/crossbeam/blob/master/src/sync/chase_lev.rs
[rfc6]: https://github.com/crossbeam-rs/rfcs/blob/master/text/2017-07-23-relaxed-memory.md
[linearizability]: https://en.wikipedia.org/wiki/Linearizability
[cppatomic]: http://en.cppreference.com/w/cpp/atomic/atomic
[dijkstra]: http://homepages.cs.ncl.ac.uk/brian.randell/NATO/nato1969.PDF
