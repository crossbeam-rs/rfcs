# Summary

This RFC proposes an implementation of work-stealing double-ended queue (deque) on Crossbeam, and
proves its correctness. FIXME: introduce the companion PR.



# Motivation

The current implementation of deque are not fully optimized yet, leaving non-negligible room for
performance improvement. However, it is unclear how to further optimize the current implementation
while guaranteeing its correctness. We aim to resolve this issue by proving an optimized
implementation.



# Detailed design

In this section, we present a pseudocode of deque, and prove that (1) it is safe in the C/C++ memory
consistency model, and (2) it is functionally correct, i.e. it acts like a deque.


## Semantics of C/C++ relaxed-memory concurrency

For the semantics of C/C++ relaxed-memory concurrency on which the deque implementation is based, we
use the state-of-art [promising semantics][promising]. For a gentle introduction to the semantics,
we refer the reader to [this blog post][synch-patterns].

One caveat of the original promising semantics is its lack of support for memory allocation. In this
RFC, we use the following semantics for memory allocation:

- In the original promising semantics, a timestamp was a non-negative quotient number: `Timestamp =
  Q+`. Now we define `Timestamp = Option<Q+>`, where `None` means the location is
  unallocated. Suppose `None < Some(t)` for all `t`.

- At the beginning, the thread's view is `None` for all the locations. When a thread allocates a
  location, its view on the location becomes `0`.

- If a thread is reading a location and it's view on the location is `None`, i.e. it is unallocated
  in the thread's point of view, the behavior is undefined.

We believe this definition is compatible with all the results presented in the [paper][promising] on
the promising semantics. We hope [the Coq formalization][promising-coq] of promising semantics be
updated accordingly soon.


## Proposed implementation

A work-stealing deque is owned by the "owner" thread, which can push items to and pop items from the
"bottom" end of the deque. Other threads, which we call "stealers", try to steal items from the
"top" end of the deque. The following is a summary of its interface:

```rust
impl<T: Send> Deque<T> { // Send + !Sync
    pub fn new() -> Self { ... }
    pub fn stealer(&self) -> Stealer<T> { ... }

    pub fn push(&self, value: T) { ... }
    pub fn pop(&self) -> Option<T> { ... } // None if empty
}

impl<T: Send> Stealer<T> { // Send + Sync
    pub fn steal(&self) -> Option<T> { ... }
}
```

Chase and Lev proposed [an efficient implementation of deque][chase-lev] on sequential consistency,
and Lê et. al. proposed [its variant for ARM and C/C++ relaxed-memory
concurrency][weak-chase-lev]. This RFC presents an even more optimized variant for C/C++.

Chase and Lev's implementation of deque consists of (1) the `bottom` index for the worker, (2) the
`top` index for both the worker and the stealers, and (3) the underlying `buffer` that contains
items. When the buffer is too small or too large, the worker may replace it with one with more
appropriate size:

```rust
struct<T: Send> Inner<T> {
    bottom: AtomicUsize,
    top: AtomicUsize,
    buffer: Ptr<Buffer<T>>,
}

impl<T: Send> Inner<T> {
    ...
}
```

The `Deque` and `Stealer` structs have a counted reference to the implementation, and delegate
method invocations to it:

```rust
struct<T: Send> Deque<T> {
    inner: Arc<Inner<T>>,
}

impl<T:Send> Deque<T> {
    fn push(...) {
        self.inner.push(...)
    }

    ...
}

...
```

The following is pseudocode for `Inner<T>`'s `fn push()`, `fn pop()`, and `fn steal()`:

```rust
pub fn push(&self, t: T) {
    'L101: let b = self.bottom.load(Relaxed);
    'L102: let t = self.top.load(Acquire);
    'L103: let mut buffer = self.buffer.load(Relaxed, epoch::unprotected());

    'L104: let cap = buffer.get_capacity();
    'L105: if b - t >= cap {
    'L106:     self.resize(cap * 2);
    'L107:     buffer = self.buffer.load(Relaxed, epoch::unprotected());
    'L108: }

    'L109: buffer.write(b % buffer.get_capacity(), t);
    'L110: self.bottom.store(b + 1, Release);
}

pub fn pop(&self) -> Option<T> {
    'L201: let b = self.bottom.load(Relaxed);
    'L202: self.bottom.store(b - 1, Relaxed);
    'L203: fence(SeqCst);
    'L204: let t = self.top.load(Acquire);
    'L205: let len = b - t;

    'L206: if len <= 0 {
    'L207:     self.bottom.store(b, Relaxed);
    'L208:     return None;
    'L209: }

    'L210: let buffer = self.buffer.load(Relaxed, epoch::unprotected());
    'L211: let mut value = Some(buffer.read((b - 1) % buffer.get_capacity()));

    'L212: if len == 1 {
    'L213:     if self.top.compare_and_swap(t, t + 1, Release, Acquire).is_err() {
    'L214:         mem::forget(value.take());
    'L215:     }
    'L216:     self.bottom.store(b, Relaxed);
    'L217: } else {
    'L218:     let cap = buffer.get_capacity();
    'L219:     if len < cap / 4 {
    'L220:         self.resize(cap / 2);
    'L221:     }
    'L221: }

    'L222: value
}

fn resize(&self, cap_new) {
    'L301: let b = self.bottom.load(Relaxed);
    'L302: let t = self.top.load(Relaxed);
    'L303: let old = self.buffer.load(Relaxed, epoch::unprotected());
    'L304: let new = Buffer::new(cap_new);

    'L305: ... // copy data from old to new

    'L306: let guard = epoch::pin();
    'L307: self.buffer.store(Owned::new(new).into_shared(guard), Release);
    'L308: guard.defer(move || old.into_owned());
}

pub fn steal(&self) -> Option<T> {
    'L401: let mut t = self.top.load(Relaxed);

    'L402: let guard = epoch::pin_fence(); // epoch::pin(), but forces fence(SeqCst)
    'L403: loop {
    'L404:     let b = self.bottom.load(Acquire);
    'L405:     if b - t <= 0 {
    'L406:         return None;
    'L407:     }

    'L408:     let buffer = self.buffer.load(Acquire, &guard);
    'L409:     let value = buffer.read(t % buffer.get_capacity());

    'L410:     match self.top.compare_exchange(t, t + 1, Release) {
    'L411:         Ok(_) => return Some(value),
    'L412:         Err(t_old) => {
    'L413:             mem::forget(value);
    'L414:             t = t_old;
    'L415:             fence(SeqCst);
    'L416:         }
    'L417:     }
    'L418: }
}
```


## Safety

We first prove that the implementation is memory-safe, i.e. it does not invoke undefined behavior
due to illegal memory accesses. We discuss two possible causes of undefined behavior: data race and
invalid pointer dereference.


### Presence of Data Races

In the C/C++ standard, if two threads race on a non-atomic object, i.e. they concurrently access it
and at least one of them writes to it, then the program's behavior is undefined. Unfortunately, in
fact, `fn push(): 'L107` and `fn steal(): 'L408` may race on `buffer`. For example, the scheduler
may stop a `steal()` invocation right after `'L402` so that `t` read in `'L401` may be arbitrarily
stale. Now, suppose that in a concurrent `push()` invocation, `b` equals to `t +
buffer.get_capacity()` and it is overwriting a value to `buffer`'s `(b % buffer.get_capacity())`-th
element. At the same time, the `steal()` invocation may wake up and read `buffer`'s `(t %
buffer.get_capacity())`-th element, incurring a data race with the `push()`.

In order to avoid this data race, we may use an atomic buffer. However, the deque's item may be
arbitrarily large, and [atomic accesses to large objects are most likely blocking][cppatomic], which
is highly undesirable. Thus there is a genuine data race in Chase and Lev's deque w.r.t. the C/C++
standards.

We make a rather bold claim: **data races are NOT undefined behavior**, but a racing reader may read
an unspecified value (or the `poison` value in the LLVM lingo), and racing writers may write values
word-by-word. This is the specification on racy accesses of promising semantics, except that the
semantics currently doesn't specify the behavior of multi-word accesses.


### Absence of Invalid Pointer Dereference

<!-- By invalid pointer dereference we mean (1) null pointer dereference, (2) use-after-free, or (3)
free-after-free. -->

It boils down to proving the safety of every access to the buffer pointed-to by `Inner`'s
`self.buffer`, (1) since the other shared objects, namely `self.bottom` and `self.top`, are just
integers, and (2) accesses to thread-local storage are straightforwardly safe. It is worth noting
that while the deque is shared among the owner (`Deque<T>`) and its stealers, only the owner is able
to call `fn push()`, `fn pop()`, and `fn resize()`, thereby modifying `self.bottom` and
`self.buffer`.

After `self.buffer` is initialized, it is modified only by the owner in `fn resize(): 'L307`. Since
elements inside a buffer is always accessed modulo the buffer's capacity (`'L109`, `'L211`, `'L409`)
and the buffer's size is always nonzero, there is no buffer overrun.

Thus it remains to prove that the buffer is not used after freed. Thanks to Crossbeam, we don't need
to take care of all the details of memory reclamation; as a user of Crossbeam, we only need to prove
that:

- When a buffer is deferred to be dropped (`'L308`), there is no longer a reference to the buffer in
  the shared memory, and no concurrent mutator introduces the reference to the memory again.

  You can easily check these properties because the owner basically "owns" the buffer: only the
  owner introduces/eliminates references to a buffer to/from the shared memory. In particular,
  before a buffer is deferred to be dropped at `'L308`, the only reference to the buffer via
  `self.buffer` is removed at `'L307`.

- With an `unprotected()` guard, we should not defer to drop an object that another thread is
  accessing, and should not access an object that another thread is deferring to drop.

  It is indeed the case because (1) a buffer is deferred to be dropped only by the owner with a
  protected guard, and (2) stealers do not use an unprotected guard.



## Functional Correctness

A more interesting question is: does it act like a deque?

In order to answer the question, we first define what does the phrase "act like" means. We say a
shared object acts like a deque if (1) it is **linearlizable** as a deque, and (2) a matching pair
of `push()` and `steal()` synchronize like a matching pair of a release-store and an acquire-load.


### Specification 1: Linearizability

More precisely, a shared object is a linearizable as a deque if the following holds:

> Suppose that multiple threads invoke methods (i.e. `push()`, `pop()`, `steal()`) on the shared
> object in a single execution. Then there exists a permutation `I_1`, ..., `I_n` of those
> invocations, which we call **"linearization order"**, denoted by `<`, that satisfies the following
> properties:
>
> - (VIEW) For all `x` and `y`, if `I_x -view-> I_y`, then `x < y` holds;
>
> - (SEQ) The invocations `I_1`, ..., `I_n` return outputs **as if** the methods are sequentially
>   (i.e. non-concurrently) executed to a deque one-by-one in the linearization order.

Here, by `view_beginning(j)` and `view_end(j)` we mean the thread `j`'s view at the beginning and
the end of the invocation. A view `v1` is less than or equal to another view `v2`, denoted by `v1 <=
v2`, if for any location `l`, `v1[l] <= v2[l]` holds; and `v1` is less than `v2`, denoted by `v1 <
v2`, if (1) `v1 <= v2`, and (2) there exists a location `l` such that `v1[l] < v2[l]`. By `j_x
-view-> j_y` we mean `view_end(j_x) < view_beginning(j_y)`.

The condition `(VIEW)` is a view-oriented interpretation of a similar condition in the [the
traditional definition of linearizability][linearizability]. What is unique in `(VIEW)` is that it
cannot properly distinguish invocations with the same view. For example, suppose the client code
looks like:

```rust
fn client() {
    i_1();
    i_2();
}
```

and `view_beginning(i_1) = view_end(i_1) = view_beginning(i_2) = view_end(i_2)`. By definition, `i_2
-> i_1` is a legit linearization order, yet morally `i_1` should be ordered before `i_2` because it
is so in the _program order_ (think: the execution order in a single thread). However, we do not
regard it a problem: if `i_1` and `i_2` do not change the view, they are read-only, and should not
change the state of the shared object. Thus it doesn't matter whether `i_1` is considered to be
before or after `i_2`.  <!-- If we want to be pedantic, we may alternatively require every method to
write something to a --> <!-- thread-local storage, effectively disallowing that the views at -->
<!-- the beginning and the end should differ. We can use this storage only in the proof, and
optimize out --> <!-- in the runtime. -->

The condition `(SEQ)` needs some clarification: in particular, what does "as if ... a deque" mean?
Let's first define a *deque state* as a triple `(t, b, A)`, where `t` is the top index, `b` is the
bottom index, and `A` is the array of the values within the indexes `[t, b)`. A `push()` method
invocation increments the bottom index `b`, and push the input value at the end of `A`. A `pop()`
method invocation decrements the bottom index `b` and pop the last value from `A`, if `t < b`;
otherwise, touch nothing and return `EMPTY`. A `steal()` method invocation increments the top index
`t` and pop the first value from `A`, if `t < b`; otherwise, touch nothing and return `EMPTY`. By `S
-(I,R)-> S'` we denote the described *transition relation* from a deque state `S` into `S'` by the
method invocation `I` returning `R`. Then `(SEQ)` can be formally defined as follows:

> There exists `(t_i, b_i, A_i)` for each `i` such that for all `i`, `(t_i, b_i, A_i)
> -(signature(I_i),ret(I_i))-> (t_(i+1), b_(i+1), A_(i+1))` holds.

Here, `signature(I_i)` and `ret(I_i)` are the function call signature and the return value of `I_i`.


### Specification 2: Synchronization of `push()` and `steal()`

In addition to linearizability, we require that matching `push()` and `steal()` operations should
synchronize like a matching pair of a release-store and an acquire-load:

> (SYNCH) If a value is `push()`ed by an invocation `I` and then `steal()`ed by `J`, then
> `view_beginning(I) <= view_end(J)` holds.

Note that a similar property for a matching pair of `push()` and `pop()` is a corollary of
linearizability, as only the owner is able to call `push()` and `pop()` and the `push()` should be
called before the `pop()` in the program order.


### Construction of Linearization Order

Consider the invocations to the deque in an execution. For the owner's invocations, the program
order is the only possible linearization among them. Let's assume that `O_0`, ..., `O_(o-1)` is the
owner's invocations, sorted according to the program order. We construct a full linearization order
by inserting stealers' invocations into it.

Note that every owner's invocation writes to `bottom`, and every stealers' invocation reads from
`bottom`. Let `WF_i` and `WL_i` be `O_i`'s first and last write to `bottom`, and `G_i` be the set of
stealers' invocations defined as follows:

- If a stealer's invocation `S` reads `WL_i` from `bottom`, then `S ∈ G_i`.

- If the value `S` reads from `WF_i` and `WF_i ≠ WL_i`, then `O_i` should be `pop()` and `WF_i` be
  written at `'L202`.
  + If `S` returns a value, then `S ∈ G_(i-1)`.
  + If `S` returns `EMPTY`, then `S ∈ G_i`.

- If a stealer's invocation `S` reads from the initial value of `bottom`, then `S ∈ G_(-1)`.

We will insert the invocations in `G_i` between `O_i` and `O_{i+1}`. Inside a "group" `G_i`, we give
the linearization order as follows:

- Let `STEAL^x` be the set of steal invocations in which an element at the index `x` is stolen, and
  `STEAL_EMPTY` be the set of steal invocations in which a stealer fails to steal an element because
  the deque is empty. Let `STEAL` be `union_x {STEAL^x}`.

- Within `G_i`, place `STEAL` invocations first, and then `STEAL_EMPTY` invocations.

- If there are multiple `STEAL` invocations, order `STEAL^x` before `STEAL^y` if `x < y`.

- If there are multiple `STEAL_EMPTY` invocations, order `I` before `J` if `I -view-> J`. (Note that
  `-view->` relation is acyclic; and there can be multiple possible linearizations.)


### Proof of `(VIEW)`

For `(VIEW)`, it is sufficient to prove that:

1. `(VIEW-OWNER-STEALER)`: for all `i <= j` and `S ∈ G_j`, it is not the case that `S -view-> O_i`.
2. `(VIEW-STEALER-OWNER)`: for all `i < j` and `S ∈ G_i`, it is not the case that `O_j -view-> S`.
3. `(VIEW-STEALER-INTER-GROUP)`: for all `i < j`, `S_i ∈ G_i` and `S_j ∈ G_j`, it is not the case
   that `S_j -view-> S_i`.
4. `(VIEW-STEALER-INTRA-GROUP)`: for all `i` and `S, S' ∈ G_i`, if `S` is placed before `S'`, then
   it is not the case that `S' -view-> S`.

(Note that what would be `(VIEW-OWNER-OWNER)` is obvious.) 

> Auxiliary Lemma

For arbitrary `i`, since `O_(i-1)` wrote `WF_(i-1), WL_(i-1)` and `O_i` wrote `WF_i, WL_i`, we have
`Timestamp(WL_(i-1)) <= view_beginning(O_i)[bottom] < Timestamp(WF_i)`. Similarly, we have
`Timestamp(WL_i) <= view_end(O_i)[bottom] < Timestamp(WF_(i+1))`.

For arbitrary `i` and `S ∈ G_i`, since `S` read `WF_i` or a later value, we have `Timestamp(WF_i) <=
view_end(S)[bottom]`. Also, since `S` read a value earlier than `WL_(i+1)`, we have
`view_beginning(S)[bottom] < Timestamp(WL_(i+1))`.

> Proof of `(VIEW-OWNER-STEALER)`.

Since `view_beginning(O_i)[bottom] < Timestamp(WF_i) <= Timestamp(WF_j) <= view_end(S)[bottom]`, it
is not the case that `S -view-> O_i`.

> Proof of `(VIEW-STEALER-OWNER)`.

Since `view_beginning(S)[bottom] < Timestamp(WL_(i+1)) <= Timestamp(WL_j) <= view_end(O_j)[bottom]`,
it is not the case that `O_j -view-> S`.

> Proof of `(VIEW-STEALER-INTER-GROUP)`.

We have `view_beginning(S_i)[bottom] < Timestamp(WL_(i+1))` and `Timestamp(WF_j) <=
view_end(S_j)[bottom]`. Thus if either `i < j`, `view_beginning(S_i)[bottom] < Timestamp(WF_(i+1))`
or `Timestamp(WL_j) <= view_end(S_j)[bottom]`, then it is not the case that `S_j -view-> S_i`.

Now suppose otherwise. Then `S_i` and `S_j` both read `bottom` from `WF_i = WF_j`. Also, since `S_i`
returns a value, the value `S_i` read from `top` at `'L401` should be `< Value(WF_i)`. On the other
hand, since `S_j` returns `EMPTY`, the value `S_j` read from top at `'L401` should be `>=
Value(WF_i)`. Thus it is not the case that `S_j -view-> S_i`.

> Proof of `(VIEW-STEALER-INTRA-GROUP)`.

Case 1: `S, S' ∈ STEAL`. 

Suppose `S` read the value `y` from `top` at `'L401`, and `S'` read the value `w` from `top` at
`'L401`. By the construction, `y < w`. Thus it is not the case that `S' -view-> S`.

Case 2: `S, S' ∈ STEAL_EMPTY`. Obvious from the construction.

Case 3: `S ∈ STEAL` and `S' ∈ STEAL_EMPTY`. 

Suppose that the value of `WL_i` is `b`, `S` read the value `x` from `bottom` at `'L404` and `y`
from `top` at `'L401`, and `S'` read the value `z` from `bottom` at `'L404` and `w` from `top` at
`'L401`. Since `S` and `S'` are in `G_i`, [`x = b` or `x = b-1`], and [`z = b` or `z = b-1`] (where
the message with the value `b-1` can be read is either from `O_i` or `O_(i+1)`). From the fact that
`S` succeeded in stealing a value, we have `y < x <= b` and thus `y <= b-1`; similarly, from the
fact that `S'` failed in stealing a value, we have `w >= z >= b-1`.

If `y < w`, then `y` is coherence-before `w` and the conclusion follows. So suppose otherwise: `w <=
y`. Then we have `b-1 <= w <= y <= b-1`, and thus `y = w = b-1`, `x = b`, and `z = b-1`. So `x` is
coherence-before `z` and the conclusion follows.


## Proof of `(SEQ)` and `(SYNC)`

Let `I_0`, ..., `I_(n-1)` be the invocations sorted according to the constructed linearization
order. In addition to `(SEQ)` and `(SYNC)`, we will simultaneously prove:

> `(CONTENT)`: for all `i` and `x ∈ [t_i, b_i)`, there exists a `push()` invocation into `x` in
> `I_0, ..., I_{i-1}`; and `A_i[x]` is the value inserted by the last such invocation.

FIXME: `t_i, b_i, A_i` are existentially quantified. `(SEQ)`, `(SYNC)`, and `(CONTENT)` should be
satisfied with the same existential variables.

We prove that `{I_i}` satisfies `(SEQ)`, `(SYNC)`, and `(CONTENT)` by induction on `n`: suppose
`I_0`, ..., `I_(i-1)` satisfies `(SEQ)`, `(SYNC)`, and `(CONTENT)`, and let's prove that `I_i` also
satisfies `(SEQ)`, `(SYNC)`, and `(CONTENT)`. We prove for each case of `I_i`.

- Case 1: `I_i` is `push()`.

  Quite obvious.

- Case 2: `I_i` is `pop()`, and it takes the "normal path" (`len >= 2` and goes to `'L218`).

  Let `x` be the value `I_i` read from `bottom` at `'L201`, and `y` be the value `I_i` read from
  `top` at `'L204`. Then we have `x = b_i`, as `bottom` is modified only by the writer. We also
  prove `t_i <= y+1`. Consider the invocation `I` that writes `y+2` to `top`, if exists. (Otherwise,
  `t_i <= y+1` should obviously hold.) If `I` is `pop()`, then `I` should be linearized after `I_i`
  thanks to the coherence of `top`; if `I` is `steal()`, by positive piggybacking synchronization of
  the SC fences from `I_i` to `I`, `I` should load a value that is coherence-after-or `WL_i` from
  `bottom`.  Thus `I ∈ G_j` for some `j >= i` and `I` is linearized after `I_i`. Thus `t_i <= y+1`
  holds.

  Since `I_i` takes the normal path, we have `t_i - 1 <= y <= x-2 = b_i - 2`, and thus `t_i <
  b_i`. So it is legit to pop a value from the bottom end of the deque and decrements `bottom`.
  
  FIXME: the right value?

- Case 3: `I_i` is `pop()`, and it doesn't take the normal path.

  Let `x` be the value `I_i` read from `bottom` at `'L201`, and `y` be the value `I_i` read from
  `top` at `'L204`. Similarly to the above case, we have `x = b_i`. We also prove `y <= t_i` as
  follows. Consider the invocation `I` that writes `y` to `top`. If `I` is `pop()`, then `I` should
  be linearized before `I_i` thanks to the coherence of `top`; if `I` is `steal()`, by positive
  piggybacking synchronization from `I`'s release-store at `'L410` to `I_i`'s acquire-load at
  `'L204`, the value `I` read from `bottom` at `'L404` should be coherence-before `WL_i`. So `I ∈
  G_j` for some `j < i`, and thus `I` is linearized before `I_i`.

  If `x <= y`, then `I_i` goes to `'L207`, restores the original value of `bottom`, and returns
  `EMPTY`. It is legit because we have `b_i = x <= y <= t_i`.

  Otherwise, since `I_i` doesn't take the normal path, it went to `'L213` so that `x = y+1`.

  If the (strong) compare-and-swap (CAS) at `L213` fails, then there should be a succeeding
  `steal()` invocation `I` such that writes `y+1` to `top`. Then by positive piggybacking
  synchronization from `I`'s release-store at `'L410` to `I_i`'s acquire-load at `'L213`, the value
  `I` read from `bottom` at `'L404` should be coherence-before `WL_i` written at `'L216`. (Here, it
  is important that the CAS at `'L213` is strong.) So `I ∈ G_j` for some `j < i`, and thus `I` is
  linearized before `I_i`. Which means `y+1 <= t_i`, and thus `b_i = x = y+1 <= t_i`. Thus it is
  legit to return `EMPTY`.

  Now suppose the CAS at `'L213` succeeds. Let's prove that `t_i <= y`. Consider the invocation `I`
  that writes `y+2` to `top`, if exists. (Otherwise, `t_i <= y` should obviously hold.) If `I` is
  `pop()`, then `I` should be linearized after `I_i` thanks to the coherence of `top`; if `I` is
  `steal()`, by positive piggybacking synchronization of the SC fences from `I_i` to `I`, `I` should
  load a value that is coherence-after-or `WF_i` from `bottom`. However, it cannot be `WF_i` because
  `Value(WF_i) = x-1 = y`, while `I` should load a value `>= y+2`. Thus `I ∈ G_j` for some `j >= i`
  and `I` is linearized after `I_i`. Thus `t_i <= y` holds. Then `t_i <= y < y+1 = x = b_i`, and it
  is legit to steal the value from the `top` end of the deque and increment `top`.

  FIXME: the right value?

- Case 4: `I_i` is `steal()` and it returns a value.

  Let `x` be the value `I_i` read from `bottom` at `'L404`, and `y` be the value `I_i` read from
  `top` at `'L401`. Then either `x = b_i` or `x = b_i - 1` holds by the definition of the owner
  methods `push()` and `pop()`.

  We also prove `t_i <= y` as follows. Consider the invocation `I` that writes `y+2` to `top`. If
  `I` is `pop()` whose last write to `bottom` is `WL_I`, then `I` should have read `y+1` from `top`
  at `'L204`. By positive piggybacking synchronization from `I_i`'s release-store at `'L410` to
  `I`'s acquire-load at `'L204`, `x` should be a value coherence-before `WL_I`. `I_i` should be
  linearized before `I`, and `t_i <= y` holds. If `I` is `steal()`, by positive piggybacking
  synchronization from `I_i`'s release-store at `'L410` to `I`'s acquire-load at `'L401-'L402`, the
  value `I` read from `bottom` at `'L404` should be coherence-after-or `x`. Since `I_i` writes `y+1`
  to `top` and `I` writes `y+2` to `top`, `I_i` should be linearized before `I`, and `t_i <= y`
  holds.

  Then we have `t_i <= y < x <= b_i`, and it is legit to steal the value from the `top` end of the
  deque and increment `top`.

  FIXME: the right value?

- Case 5: `I_i` is `steal()` and it returns `EMPTY`.

  Let `x` be the value `I_i` read from `bottom` at `'L404`, and `y` be the value `I_i` read from
  `top` at `'L401`. Then `x <= y` holds since `I_i` returns `EMPTY`. Also, either `x = b_i` or `x =
  b_i - 1` holds by the definition of the owner methods `push()` and `pop()`.

  + Case `x = b_i`.

    We prove `y <= t_i` as follows. Consider the invocation `I` that writes `y` to `top`. If `I` is
    `pop()`, then `I` should be linearized before `I_i` thanks to the coherence of `top`; if `I` is
    `steal()`, by positive piggybacking synchronization from `I`'s release-store at `'L410` to
    `I_i`'s acquire-load at `'L204`, the value `I` read from `bottom` at `'L404` should be
    coherence-before the values written by `I_i`. So `I ∈ G_j` for some `j < i`, and thus `I` is
    linearized before `I_i`.
  
    Then we have `b_i = x <= y <= t_i`.

  + Case `x = b_i - 1`.
  
    FIXME.

    Then we have `b_i = x+1 <= y+1 <= t_i`.



-------------

> Lemma (POP-UNUSUAL): If `O_i` is a `pop()` invocation and `O_i` didn't go through the "normal
> path" at `'L218`, then `G_i ⊆ STEAL_EMPTY`.

We prove by contradiction: suppose `S` is an invocation in `G_i \ STEAL_EMPTY`, and let's derive a
contradiction.

Let `x` be the value `O_i` read from `bottom` at `'L201`, and `y` be the value `O_i` read from `top`
at `'L204`. Then `O_i` writes `x-1` to `bottom` at `'L202`, and then writes `x` to `bottom` at
`'L207` or `'L216`. Also, `x-1 <= y` holds from the fact that `O_i` didn't go through the normal
path. Let `z` be the value `S` read from `bottom` at `'L404`, and `w` be the value `S` read from
`top` at `'L401`. Since `S` is in `STEAL`, `w <= z-1` and `S` successfully updated `top` from `w` to
`w+1` at `'L410`. By the construction of `G_i`, `z <= x` should hold. Thus we know `w <= z-1 <= x-1
<= y`.

If `w <= y-1`, then there is a positive piggybacking synchronization from `S`'s `'L410` to `O_i`'s
`'L204` via `top`. So it is impossible for `S` to read `W_i` or later from `bottom` at `'L404`,
contradicting the assumption that `S` is in `G_i`.

If `w = y`, then we have `z = x = w+1` from the inequality. Thus `O_i` should have failed the
(strong) compare-and-swap at `'L213`, reading the value written by `S` at `'L410` or a later
value. We can derive a contradiction similarly to the above case.


------------

Suppose there are `n` invocations to the deque in an execution. We classify the invocations as
follows:

- `push^x`: an element at the index `x` is pushed by the owner;
- `pop^x`: an element at the index `x` is popped by the owner in the fast path, i.e. the case that
  the branch at `'L212` is not taken.
- `pop_steal^x`: an element at the index `x` is popped by the owner in the slow path, i.e. the case
  that the branch at `'L212` is taken.
- `pop_empty^x`: the owner fails to pop an element because it's empty, and it read `x` from
  `self.bottom` at `'L201`.
- `steal^x`: an element at the index `x` is stolen.
- `steal_empty^x`: a stealer fails to steal an element because it's empty, and it read `x` from
  `t`. Also, it didn't read `b` from the value stored in `'L202`.
- `steal_empty_irregular^x`: similar to `steal_empty()^x`, but it read `b` from the value stored in
  `'L202`.

Furthermore, we define the following super-classes:

- `OWNER` = `Union_i {push^x U pop^x U pop_steal^x U pop_empty^x}`
- `STEALER` = `Union_i {steal^x U steal_empty^x U steal_empty_irregular^x}`
- `STEAL^x` = `pop_steal^x U steal^x`
- `EMPTY^x` = `pop_empty^x U steal_empty^x U steal_empty_irregular^(x-1)`

We construct a linearization order `L` for a given program execution as follows:

- List `OWNER` invocations according to the program order. Let `L` be such an order.

- Insert `STEALER` invocations in `L` as follows. For each `x`, in the increasing order from 0 to
  infinity, until all invocations are inserted in `L`:

    + Insert `EMPTY^x` invocations one-by-one in `L`. Each invocation `I` should be inserted after
      `STEAL^(x-1)` invocations, and after those invocations `J` such that `J -view-> I` holds
      (cf. the `(VIEW)` rule). Insert `I` at the earliest possible position.

    + Insert the `steal^x` invocation, if exists, in `L`. It should be inserted after `push^x`,
      `STEAL^(x-1)`, and `EMPTY^x`, and after those invocations `J` such that `J -view-> steal^x`
      holds. Insert it at the earliest possible position.


### Auxiliary Lemma

Before delving into the main proof, we first prove several lemmas on `L`.


> Lemma (VIEW-OWNER): Suppose `L_i` is in `OWNER`, and `L_i -view-> L_j`. Then `i < j` holds.

If `L_j` is also in `OWNER`, then `i < j` by the construction of `L`. Otherwise, `L_j` is in
`STEALER`, then `L_j` should have been inserted after `L_i` by the construction of `L`, concluding
that `i < j`.


> Lemma (VIEW-STEALER): Suppose `i < k`, `L_i` is `OWNER`, and `L_k` is `STEALER`. Then there exists
> `j` such that:
>
> - `i <= j <= k`;
>
> - `L_i -view-> L_j` or `i = j`; and
>
> - If `L_k` is `EMPTY^x` for some `x`, then `L_j` is `push^y` for some `0 <= y < x`, `STEAL^y` for
>   some `0 <= y < x`, or `EMPTY^y` for some `0 <= y < x`.  Otherwise, if `L_k` is `steal^x` for
>   some `x`, then `L_j` is `push^y` for some `0 <= y <= x`, `STEAL^y` for some `0 <= y < x`, or
>   `EMPTY^y` for some `0 <= y <= x`.

FIXME


### Main Proof

We prove by induction that every suffix of `L` is linearization. Let `L_j` be the `j`-th invocation
in `L` (the index begins at 0), and `L[a..b)` be the sublist of `L` from `a`-th to `(b-1)`-th
invocations. Then `L[0..j)` is the suffix of `L` with `j` invocations.  `L[0..0)` is trivially
linearization. Now let's prove that if `L[0..j)` is a linearization, then so is `L[0..(j+1))`. Let
`b_j` and `t_j` be the bottom and top index after `L[0..j)` according to the sequential
specification of deque. We do a case analysis on `L_j`, which is the last invocation of
`L[0..(j+1))`:

- Case that `L_j` is classified as `push^x`.

  + `(VIEW)`: by `(VIEW-OWNER)`.

  + `(SEQ)`: obvious.

    <!-- Since only the owner writes to `self.bottom`, the value read at `'L101` in `L_j` equals -->
    <!-- to `b_j` and the value written at `'L110` in `L_j` equals to `b_(j+1)`. Thus `(SEQ)` trivially -->
    <!-- holds for `L_j`. -->

- Case that `L_j` is classified as `pop^x`.

  + `(VIEW)`: by `(VIEW-OWNER)`.

  + `(SEQ)`: Since only the owner writes to `self.bottom`, the value read at `'L201` in `L_j` equals
    to `b_j = x+1` and the value written at `'L202` in `L_j` equals to `b_(j+1) = x`. Let `y` be the
    value read from `self.top` at `'L204`. Since `L_j` is `pop^x`, the inequality `y <= x-1` should
    hold.

    For `(SEQ)`, it is sufficient to prove that `t_j <= x` holds, and the value read at `'L211` is
    actually the value pushed by `push^x`.

    We prove `t_j <= x` by contradiction: let's suppose `t_j >= x+1`. Since `self.top` is
    incremented only by `STEAL` invocations, there should be `i < j` such that `L_i` is
    `STEAL^x`. If it is `pop_steal^x`, then `y >= x+1` should hold by the coherence on `self.top`,
    which is a contradiction. Otherwise, `L_i` is `steal^x`, and the value read from `self.top` at
    `'L401` in `L_i` is `x`. Let `z` be the value read from `self.bottom` at `'L404` for the last
    iteration of the loop at `'L403`. Then by the condition at `'L405`, the inequality `z >= x+1`
    should hold. Since `y <= x-1`, which means `L_j`'s load from `self.top` at `'L204` is
    coherence-before `L_i`'s load from `self.top` at `'L401`, the view of `L_j` at `'L203` should be
    less than the view of `L_i` at `'L403` via positive piggybacking synchronization of `SeqCst`
    fences. Thus `z` is coherence-after the value written in `L_j` at `'L202`. (`z` cannot be the
    value written at `'L202`, which is `x`, since `z` should be bigger than `x`.) Thus there should
    be a `push^x` invocation after `L_j`. Let it be `L_k` where `j < k` holds. Then by the
    construction of `L`, `k < i` should hold, which contradicts with `i < j < k`.

    FIXME: it returns the right value?

- Case that `L_j` is classified as `pop_steal^x`.

  + `(VIEW)`: by `(VIEW-OWNER)`.

  + `(SEQ)`: Similarly to the case for `pop^x`, the value of `self.bottom` read at `'L201` in `L_j`
    equals to `b_j = x+1`, the value written at `'L202` in `L_j` equals to `x`, and the value
    written at `'L216` equals to `b_(j+1)=x+1`. Also, the value of `self.top` read at `'L204` in
    `L_j` is `x`.

    Let `y` be the value read from `self.top` at `'L204`. Since `L_j` is `pop^x`, the inequality `y
    <= x-1` should hold.

    FIXME

- Case that `L_j` is classified as `pop_empty^x`.

  + `(VIEW)`: by `(VIEW-OWNER)`.

  + `(SEQ)`: FIXME

- Case that `L_j` is classified as `steal^x`.

  + `(VIEW)`: FIXME
  + `(SEQ)`: FIXME
  + `(SYNCH)`: FIXME

- Case that `L_j` is classified as `steal_empty^x`.

  + `(VIEW)`: FIXME
  + `(SEQ)`: FIXME

- Case that `L_j` is classified as `steal_empty_irregular^x`.

  + `(VIEW)`: FIXME
  + `(SEQ)`: FIXME



# Alternatives

## The current implementation

A reader may notice that the pseudocode differs from [the current implementation in
Crossbeam][current-impl]. FIXME: We believe the current implementation is buggy w.r.t. the C11
memory model, because it uses SC updates that do not provide the interleaving property. See [RFC
#6][rfc6] for more details.

## Target-dependent implementation

Alternatively, we can write a deque for each target architecture in order to achieve better
performance. Indeed, [this paper][FIXME] presented a variant of Chase and Lev's deque which issues
less `MFENCE` in `fn FIXME()` than the x86 compilation result of the proposed implementation. Also, a
variant in [this paper][weak-chase-lev] for POWER doesn't issue an `isync` fence, while the proposed
implementation issues one. These further optimizations are left as future work.




# Unresolved questions

Is it *really* the most efficient implementation in the C11 memory model?

FIXME: pop now loads `top` with `Acquire`. Is it necessary?

Is there any soundness gap in the description above? More ambitiously, can we formally verify the
correctness of the proposed implementation?


[chase-lev]: https://pdfs.semanticscholar.org/3771/77bb82105c35e6e26ebad1698a20688473bd.pdf
[weak-chase-lev]: http://www.di.ens.fr/~zappa/readings/ppopp13.pdf
[impl]: https://github.com/jeehoonkang/crossbeam-deque
[crossbeam-rs]: https://github.com/crossbeam-rs
[promising]: http://sf.snu.ac.kr/promise-concurrency/
[promising-coq]: https://github.com/snu-sf/promising-coq
[synch-patterns]: https://jeehoonkang.github.io/2017/08/23/synchronization-patterns.html
[current-impl]: https://github.com/crossbeam-rs/crossbeam-deque
[rfc6]: https://github.com/crossbeam-rs/rfcs/blob/master/text/2017-07-23-relaxed-memory.md
[linearizability]: https://en.wikipedia.org/wiki/Linearizability
[cppatomic]: http://en.cppreference.com/w/cpp/atomic/atomic
[dijkstra]: http://homepages.cs.ncl.ac.uk/brian.randell/NATO/nato1969.PDF
